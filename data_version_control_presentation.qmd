---
title: "Data Version Control"
jupyter: python3
author:
  name: Mainye B
  site-url: nyab.notion.com
format:
  html: 
    code-fold: true
    theme: darkly
    toc: true
    number-sections: true
    colorlinks: true
---

# What is it?
Data version control is way of making a reproducible journal to replicate your data science workflow. Imagine when you are working with teams everyone has their own way of doing things but how can we make a consensus to have unified way of 
working together so that you don't step on each others toes. On the other hand, 
is there a way of managing data science projects a bit easier to be able to track project a bit better? We will discuss that in this presentation.

They are several tools that have been created to address this problem. They include the following:

- [DVC](https://dvc.org/)
- [Mlflow](https://mlflow.org/)
- [Neptuneai](https://neptune.ai/)
- [Delta Lake](https://delta.io/)
- [Metaflow](https://metaflow.org/)

::: {.callout}
We'll go through DVC, great expectations and Makefiles
:::

# Why is it important?
As someone who has worked on various projects in data science and machine learning. I have discovered that the path from idea to product needs a fricitionless workflow this will allow you to think about implementing ideas than handling all that goes on in the background.

It is important mostly because it can get very confusing when handling projects and keeping track of your experiments since in data science we don't have predefined outputs. We can make a report, dashboard, an application and API. They are so many things that go into that data importing, EDA, feature engineering and modeling which can take so many routes to reach your destination.

> add image of a winding path

## Needs
- How can we track different parts of work?
- How can we record hyperparameters in different versions of our experiments?
- How about storing metadata of our projects like models and slices of data?
- How about metrics how can those be put together in a more unified way?
- Can I replicate their work 100% or 95%?

> All the solutions above can help us with that.

### Examples


::: {.callout-important}
**[Medical Cost Personal Datasets](https://www.kaggle.com/datasets/mirichoi0218/insurance)**
:::

::: {.callout-tip}
**[Telco dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)**
:::

The dataset has a number of observations and measurements that a crucial for a prediction task which is finding churn. That is, the likelihood that a client will stop using the telecommunications company. That is, if you are looking at the second dataset.


Other very common metrics that you can be asked to calculate in the data science team include:

| Metric 	| Explanation 	| Associated link 	|
|---------|:-----|------:|
| Hypothesis testing 	| Making the website better via focus group testing. 	| https://medium.com/@gajendra.k.s/hypothesis-testing-33aaeeff5336 	|
| Conversion rate 	| time it takes for a client to move from discovery to becoming a paying customer. 	| https://www.geeksforgeeks.org/conversion-rate-what-is-it-how-to-calculate-it/ 	|
| Customer life time value (LTV) 	| how much a client(s) will generate in their lifetime. 	| https://www.datacamp.com/tutorial/customer-life-time-value 	|
| Recommendation systems 	| how can we sell cross sell our existing products better 	| https://medium.com/@Karthickk_Rajah/clustering-based-algorithms-in-recommendation-system-205fcb15bc9b 	|
| Optimization 	| adjusting cost of product this involves using specific techniques to find the maximum or minimum value of something to reap better revenues 	| https://towardsdatascience.com/production-fixed-horizon-planning-with-python-8dd38b468e86 	|


### Data science process   

We will be referencing a cool notebook that someone in the kaggle community had done. Here's the original [notebook](https://www.kaggle.com/code/hely333/eda-regression).

The person did are really cool job. However, I wish more one hot encoding was done and exploring techniques such as OneR were done. We'll explore that later. At the moment, let's set out attention to the data science process. Add a more detail from the wiki and the book below.



::: {#fig-datasci layout-ncol=2}
[![Data science process](Screenshot from 2023-02-13-10-57-10.png)](https://www.manning.com/books/data-science-with-python-and-dask){#fig-process}

![Transforming-data](Screenshot from 2023-02-13-10-57-41.png){width=100}

What is done in data science
:::

Often times you can easily just make a notebook, and your work is done. They are tools that allow you to do [scheduled notebook reruns](https://www.kaggle.com/discussions/getting-started/293861) on kaggle, using [papermill](https://papermill.readthedocs.io/en/latest/) and [Sagemaker](https://towardsdatascience.com/how-to-schedule-jupyter-notebooks-in-amazon-sagemaker-d50fa1c8c0ad).

## Try something different with DVC and Makefiles

### Makefile
In most Unix systems (Mac Os and Linux) you'll find that the `make` command is already installed. If not it very easy to install it. 

::: {.callout-tip}
How to install


```{bash}
# update packages
sudo apt-get update
# just say yes to make
sudo apt-get -y install make
# what version was installed
make -v
```
:::

Using these files makes it easy to hide the complexity of running commands that you require to follow best practices as an example:

> Running in bash
```{bash}
#| echo: false

# This code runs the pylint tool with specific configurations to check for errors in Python files.
# The `--disable=R,C` flag disables the pylint checks for code style and convention violations.
# The `--errors-only` flag ensures that only error messages are displayed.
# The `*.py utils/*.py testing/*.py` argument specifies the files and directories to be checked by pylint.
pylint --disable=R,C --errors-only *.py utils/*.py testing/*.py
```

Code Linting Linting is crucial for maintaining high-quality code. It helps catch errors and inconsistencies early on, reducing bugs and improving readability.

Why Lint?

* Reduced bugs: Catch errors before runtime.
* Improved readability: Enforce consistent coding standards.
* Faster development: Identify issues quickly.

> Within your Makefile

```{bash}
#| echo: false
lint: activate install format
	# flake8 or #pylint
	pylint --disable=R,C --errors-only *.py utils/*.py testing/*.py
```

> In Terminal

```{bash}
#| echo: false
make lint
```


::: {.callout-tip}
Instead of memorizing long commands you can store them in a Makefile and run them in a single command
for example `make all` will run each command until the end of the file. Also, [Continous Integration/Continous Deployment](https://www.youtube.com/watch?v=2wSBAkJGcug)
:::

### Using a Makefile for Machine Learning Workflow
At this juncture, you are probably acknowledging how much a Makefile is amazing. Get this you can use it with any language you prefer for data science and machine learning. Here are more [examples in Julia and R](https://gist.github.com/Shuyib/ae87774fd82c69706803725db9a681dc)

Let create a Makefile to assist us with **Making** a machine learning workflow to help us handle the project better.


